<!DOCTYPE html>
<html lang="zh-cn" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs | JJ&#39;s Blog</title>
<meta name="keywords" content="KV Cache, MLLM, Paper Note">
<meta name="description" content="
Conference: NeurIPS&#39;25
github: https://github.com/Theia-4869/CDPruner

My Thoughts
ç›¸è¾ƒäº Attention-based methods ä¸­çš„ attention shift é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰ çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† CDPrunerï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚

Motivations
åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š

LLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º 576 tokensï¼›
LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ 2,880 tokensï¼›
LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ 200K visual tokensï¼›
LongVILA èƒ½å¤„ç† 6,000 å¸§å¹¶äº§ç”Ÿ è¶…è¿‡ 1M visual tokensï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚


Challenges

ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š">
<meta name="author" content="">
<link rel="canonical" href="https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/">
<link crossorigin="anonymous" href="https://jjl357.github.io/blog/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css" integrity="sha256-NDzEgLn/yPBMy&#43;XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://jjl357.github.io/blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://jjl357.github.io/blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://jjl357.github.io/blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://jjl357.github.io/blog/apple-touch-icon.png">
<link rel="mask-icon" href="https://jjl357.github.io/blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="zh-cn" href="https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><script type="text/javascript"
        async
        src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>
<meta property="og:url" content="https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/">
  <meta property="og:site_name" content="JJ&#39;s Blog">
  <meta property="og:title" content="Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs">
  <meta property="og:description" content="
Conference: NeurIPS&#39;25 github: https://github.com/Theia-4869/CDPruner
My Thoughts ç›¸è¾ƒäº Attention-based methods ä¸­çš„ attention shift é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰ çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† CDPrunerï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚
Motivations åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š
LLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º 576 tokensï¼› LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ 2,880 tokensï¼› LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ 200K visual tokensï¼› LongVILA èƒ½å¤„ç† 6,000 å¸§å¹¶äº§ç”Ÿ è¶…è¿‡ 1M visual tokensï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚ Challenges ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š">
  <meta property="og:locale" content="zh-cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-10-24T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-10-24T00:00:00+00:00">
    <meta property="article:tag" content="KV Cache">
    <meta property="article:tag" content="MLLM">
    <meta property="article:tag" content="Paper Note">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs">
<meta name="twitter:description" content="
Conference: NeurIPS&#39;25
github: https://github.com/Theia-4869/CDPruner

My Thoughts
ç›¸è¾ƒäº Attention-based methods ä¸­çš„ attention shift é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰ çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† CDPrunerï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚

Motivations
åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š

LLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º 576 tokensï¼›
LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ 2,880 tokensï¼›
LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ 200K visual tokensï¼›
LongVILA èƒ½å¤„ç† 6,000 å¸§å¹¶äº§ç”Ÿ è¶…è¿‡ 1M visual tokensï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚


Challenges

ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://jjl357.github.io/blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs",
      "item": "https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs",
  "name": "Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs",
  "description": "\nConference: NeurIPS'25 github: https://github.com/Theia-4869/CDPruner\nMy Thoughts ç›¸è¾ƒäº Attention-based methods ä¸­çš„ attention shift é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰ çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† CDPrunerï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚\nMotivations åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š\nLLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º 576 tokensï¼› LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ 2,880 tokensï¼› LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ 200K visual tokensï¼› LongVILA èƒ½å¤„ç† 6,000 å¸§å¹¶äº§ç”Ÿ è¶…è¿‡ 1M visual tokensï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚ Challenges ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š\n",
  "keywords": [
    "KV Cache", "MLLM", "Paper Note"
  ],
  "articleBody": "\nConference: NeurIPS'25 github: https://github.com/Theia-4869/CDPruner\nMy Thoughts ç›¸è¾ƒäº Attention-based methods ä¸­çš„ attention shift é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰ çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† CDPrunerï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚\nMotivations åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š\nLLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º 576 tokensï¼› LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ 2,880 tokensï¼› LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ 200K visual tokensï¼› LongVILA èƒ½å¤„ç† 6,000 å¸§å¹¶äº§ç”Ÿ è¶…è¿‡ 1M visual tokensï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚ Challenges ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š\nAttention-based pruningï¼šåˆ©ç”¨ text-visual attention åˆ†æ•°è¡¡é‡è§†è§‰ token çš„é‡è¦æ€§ã€‚ Similarity-based pruningï¼šä¾æ®è§†è§‰ token é—´çš„ç›¸ä¼¼æ€§ç§»é™¤å†—ä½™éƒ¨åˆ†ã€‚ ç„¶è€Œï¼Œè¿™ä¸¤ç§æ–¹æ³•å‡å­˜åœ¨å›ºæœ‰ç¼ºé™·ã€‚Attention-based æ–¹æ³•åªè€ƒè™‘é‡è¦æ€§ï¼Œå®¹æ˜“ä¿ç•™å¤§é‡é‡å¤ tokenï¼›Similarity-based æ–¹æ³•å¿½ç•¥äº†æŒ‡ä»¤ï¼ˆinstructionï¼‰çš„å…³è”æ€§ï¼Œå¯¼è‡´æ— æ³•é’ˆå¯¹é—®é¢˜è¿›è¡ŒåŠ¨æ€å‰ªæï¼Œä»è€Œæ€§èƒ½æ¬¡ä¼˜ã€‚\nâ€œHowever, as pointed out by Zhang et al. [2024b] and Wen et al. [2025a], such methods suffer from attention shift, which compromises pruning accuracy.â€\nâš  ä»€ä¹ˆæ˜¯ attention shiftï¼Ÿ (gptå›ç­” ä¸ä¸€å®šæ­£ç¡®)\nAttention shift æŒ‡åœ¨ token å‰ªææˆ–è¾“å…¥å˜åŒ–åï¼Œæ¨¡å‹çš„æ³¨æ„åŠ›åˆ†å¸ƒå‘ç”Ÿåç§»ï¼Œå¯¼è‡´åŸæœ¬é‡è¦çš„ token è¢«ä½ä¼°æˆ–ä¿¡æ¯ä¸¢å¤±ï¼Œä»è€Œé™ä½å‰ªæå‡†ç¡®æ€§ã€‚ç”±äº Transformer çš„ self-attention æ˜¯å…¨å±€ä¾èµ–çš„ï¼Œåˆ é™¤éƒ¨åˆ† token ä¼šæ”¹å˜ query-key åˆ†å¸ƒï¼Œä½¿å‰©ä½™ token çš„æ³¨æ„åŠ›é‡æ–°åˆ†å¸ƒï¼Œå¦‚æœä¸è€ƒè™‘è¿™ç§ shiftï¼ŒåŸºäºæ³¨æ„åŠ›çš„å‰ªææ–¹æ³•å®¹æ˜“å‡ºç°å†³ç­–å¤±çœŸï¼Œä¿ç•™é‡å¤ token æˆ–é—æ¼å…³é”® tokenï¼Œä»è€Œå½±å“æ¨ç†æ€§èƒ½ã€‚(Zhang et al., 2024b, â€œ[CLS] Attention Is All You Need for Training-Free Visual Token Pruning: Make VLM Inference Fasterâ€; Wen et al., 2025a, â€œToken Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?â€)\nâš  attention-based æ–¹æ³•ä¸å…¼å®¹é«˜æ•ˆå®ç°å¦‚ FlashAttention æ­¤å¤–ï¼Œattention-based æ–¹æ³•è¿˜ä¾èµ–æ˜¾å¼ attention æƒé‡ï¼Œä¸å…¼å®¹é«˜æ•ˆå®ç°å¦‚ FlashAttentionã€‚\nå› ä¸ºattention-based æ–¹æ³•ä¾èµ–æ˜¾å¼çš„ attention æƒé‡çŸ©é˜µï¼ˆattention mapï¼‰ æ¥è¯„ä¼°æ¯ä¸ªè§†è§‰ token çš„é‡è¦æ€§ï¼Œéœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­è®¿é—®å®Œæ•´çš„ Softmax(QKáµ€) ç»“æœæˆ–å…¶ä¸­çš„è¡Œå‘é‡ã€‚ä½†é«˜æ•ˆæ³¨æ„åŠ›å®ç°ï¼ˆå¦‚ FlashAttentionï¼‰çš„æ ¸å¿ƒæ€æƒ³æ­£æ˜¯é¿å…æ˜¾å¼æ„å»ºä¸å­˜å‚¨æ•´ä¸ªæ³¨æ„åŠ›çŸ©é˜µã€‚\nFlashAttention å°†æ³¨æ„åŠ›è®¡ç®—åˆ†å—ï¼ˆblock-wiseï¼‰æ‰§è¡Œï¼Œé€šè¿‡åœ¨ GPU çš„é«˜é€Ÿå¯„å­˜å™¨å’Œç‰‡ä¸Š SRAM ä¸­å³æ—¶è®¡ç®— Softmax(QKáµ€)Vï¼Œå¹¶åœ¨æ¯ä¸ªå—ç»“æŸåç«‹åˆ»ä¸¢å¼ƒä¸­é—´çš„ QKáµ€ ç»“æœä¸æ³¨æ„åŠ›æƒé‡ï¼Œä»…ä¿ç•™æœ€ç»ˆè¾“å‡ºã€‚è¿™ç§æ–¹æ³•æå¤§é™ä½äº†æ˜¾å­˜è¯»å†™å’Œå¸¦å®½å ç”¨ï¼Œä½¿å¾—æ³¨æ„åŠ›è®¡ç®—çš„å¤æ‚åº¦ä»å†…å­˜ç“¶é¢ˆï¼ˆmemory-boundï¼‰å˜ä¸ºè®¡ç®—å—é™ï¼ˆcompute-boundï¼‰ï¼Œä»è€Œå®ç°é«˜æ•ˆæ¨ç†ã€‚\nç„¶è€Œï¼Œè¿™ç§å®ç°æ–¹å¼å¸¦æ¥ä¸‰ä¸ªå…³é”®åæœï¼Œä½¿ attention-based pruning ä¸ FlashAttention ä¸å…¼å®¹ï¼š\nä¸å¯è®¿é—®æ€§ï¼šFlashAttention ä¸æ˜¾å¼å­˜å‚¨æˆ–è¿”å›å®Œæ•´çš„ attention mapï¼Œå› æ­¤æ— æ³•ç›´æ¥æå–æ¯ä¸ª token çš„æ³¨æ„åŠ›æƒé‡ï¼›è€Œ attention-based æ–¹æ³•æ°æ°éœ€è¦è¿™äº›åˆ†æ•°æ¥åˆ¤æ–­ä¿ç•™ä¸åˆ é™¤ã€‚ å­˜å‚¨ä¸æ€§èƒ½å†²çªï¼šè‹¥å¼ºè¡Œä¿®æ”¹ FlashAttention ä»¥è¾“å‡º attention mapï¼Œå°±å¿…é¡»é‡æ–°æ˜¾å¼è®¡ç®—å¹¶ç¼“å­˜ QKáµ€ å’Œ Softmax ç»“æœï¼Œè¿™ä¼šç ´åå…¶å†…å­˜å¤ç”¨æœºåˆ¶ï¼Œé‡æ–°å¼•å…¥å¤§è§„æ¨¡å†…å­˜è®¿é—®ä¸æ˜¾å­˜å ç”¨ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚ å¤šå¤´ä¸å±‚æ¬¡ä¸ç¨³å®šæ€§ï¼šä¸åŒå±‚ã€ä¸åŒå¤´çš„æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒå·®å¼‚æ˜¾è‘—ï¼Œä¸” FlashAttention å†…éƒ¨æŒ‰å—ç´¯ç§¯ Softmaxï¼Œä¼šè¿›ä¸€æ­¥å¯¼è‡´ attention å€¼åœ¨ä¸åŒåˆ†å—é—´ä¸å¯ç›´æ¥æ¯”è¾ƒï¼Œå¢åŠ äº†åŸºäº attention å€¼è¿›è¡Œç»Ÿä¸€æ’åºå’Œå‰ªæçš„éš¾åº¦ã€‚ å› æ­¤ï¼Œåœ¨é‡‡ç”¨ FlashAttention æˆ–å…¶ä»–é«˜æ•ˆæ³¨æ„åŠ›ä¼˜åŒ–ï¼ˆå¦‚ xFormersã€PagedAttentionï¼‰çš„ç°ä»£ MLLM ä¸­ï¼Œattention-based pruning æ–¹æ³•æ— æ³•ç›´æ¥ä½¿ç”¨æˆ–ä¼šç ´åæ¨ç†åŠ é€Ÿæ•ˆæœã€‚\nå› æ­¤ï¼Œä½œè€…æå‡ºä» â€œbeyond attention or similarityâ€ çš„è§’åº¦é‡æ–°æ€è€ƒ token pruningã€‚\nContributions æå‡º CDPrunerï¼šä¸€ç§ plug-and-playã€model-agnostic çš„è§†è§‰ token å‰ªææ–¹æ¡ˆï¼Œé€šè¿‡æœ€å¤§åŒ–æ¡ä»¶å¤šæ ·æ€§ï¼ˆconditional diversityï¼‰å®ç°é«˜æ•ˆåŠ¨æ€å‰ªæï¼› å°† token pruning é—®é¢˜é‡æ„ä¸º DPPï¼ˆDeterminantal Point Processï¼‰ï¼Œè”åˆè€ƒè™‘ feature similarity ä¸ instruction relevanceï¼› åœ¨å¤šç§è§†è§‰è¯­è¨€åŸºå‡†ä¸Šå®éªŒéªŒè¯ï¼ŒCDPruner åœ¨ä¸åŒå‹ç¼©ç‡ä¸‹å‡å–å¾— SOTAã€‚ Methods Determinantal Point Process (DPP) DPP æœ€åˆç”¨äºåˆ»ç”»è´¹ç±³å­ç³»ç»Ÿçš„â€œæ’æ–¥æ•ˆåº”â€ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­è¢«å¹¿æ³›ç”¨äºå»ºæ¨¡é›†åˆé€‰æ‹©çš„å…¨å±€å¤šæ ·æ€§ã€‚\nä¸ Max-Min Diversity Problem (MMDP) ä»…å…³æ³¨æç«¯æ ·æœ¬ä¸åŒï¼ŒDPP å¼ºè°ƒå…¨å±€å¹³è¡¡å’Œä»£è¡¨æ€§ã€‚ä¼ ç»Ÿ DPP ä»…è€ƒè™‘æ ·æœ¬é—´ç›¸ä¼¼åº¦ï¼Œè€Œæœ¬è®ºæ–‡åœ¨æ­¤åŸºç¡€ä¸Šå¼•å…¥ instruction relevanceï¼Œä½¿å‰ªæè¿‡ç¨‹åŒæ—¶è€ƒè™‘â€œtoken ç›¸å…³æ€§â€ä¸â€œå¤šæ ·æ€§â€ã€‚\nDPP with Token Similarity æ ¸å¿ƒæ€æƒ³ï¼š å°†è§†è§‰ token çš„ pairwise similarity å»ºæ¨¡ä¸ºä¸€ä¸ªæ ¸çŸ©é˜µ ( L )ï¼Œå¹¶é€šè¿‡æœ€å¤§åŒ–å…¶è¡Œåˆ—å¼ï¼ˆdeterminantï¼‰æ¥é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„å­é›†ã€‚\nå®šä¹‰æ¯ä¸ªè§†è§‰ token çš„ç‰¹å¾å‘é‡ä¸º ( $H^v_i \\in \\mathbb{R}^d$ )ï¼Œåˆ™ç›¸ä¼¼æ ¸çŸ©é˜µä¸ºï¼š\n$$ L_{ij} = \\frac{H^v_i \\cdot H^v_j}{|H^v_i| , |H^v_j|} $$\nç›®æ ‡æ˜¯é€‰æ‹©ä¸€ä¸ªåŒ…å« ( m ) ä¸ª token çš„å­é›† ( $S \\subset Z$ )ï¼Œä½¿å¾—ï¼š\n$$ S^* = \\arg\\max_{S \\subset Z, |S|=m} \\det(L_S) $$\nè¿™é‡Œ ( $L_S$ ) æ˜¯å¯¹åº”å­é›†çš„å­çŸ©é˜µã€‚è¡Œåˆ—å¼è¶Šå¤§ï¼Œä»£è¡¨è¯¥å­é›†åœ¨ç‰¹å¾ç©ºé—´ä¸­â€œè¦†ç›–çš„æ–¹å‘â€è¶Šå¤šï¼Œä¿¡æ¯å†—ä½™è¶Šä½ã€‚\nç›´è§‚è§£é‡Šï¼š å¦‚æœä¸¤ä¸ª token çš„ç‰¹å¾éå¸¸ç›¸ä¼¼ï¼ˆçº¿æ€§ç›¸å…³ï¼‰ï¼Œè¡Œåˆ—å¼ä¼šå‡å°ã€‚å› æ­¤ DPP å¤©ç„¶å€¾å‘ä¿ç•™â€œäº’è¡¥â€ä¿¡æ¯è€Œéé‡å¤ tokenï¼Œä»è€Œå®ç°é«˜æ•ˆä¸”å…¨å±€å‡è¡¡çš„å‰ªæã€‚\nInstruction Relevance ä¼ ç»Ÿ DPP ä»…åŸºäºè§†è§‰ç‰¹å¾æ„å»ºæ ¸çŸ©é˜µï¼Œæ— æ³•ä½“ç°è§†è§‰ token ä¸æ–‡æœ¬æŒ‡ä»¤çš„ç›¸å…³æ€§ã€‚CDPruner é€šè¿‡ä»¥ä¸‹æ­¥éª¤å¼•å…¥ æ¡ä»¶ç›¸å…³æ€§ï¼ˆconditional relevanceï¼‰ï¼š\nè·å–è§†è§‰ token è¡¨ç¤º ( $H_v \\in \\mathbb{R}^{n \\times d}$ )ï¼›\nè·å–æ–‡æœ¬åµŒå…¥ï¼ˆinstruction embeddingï¼‰ ( $\\bar{H}_q \\in \\mathbb{R}^d $)ï¼Œå…¶æ¥æºå¯ä»¥æ˜¯ï¼š\nCLIP-like text encoderï¼ˆè‹¥æ¨¡å‹å…·å¤‡åŒç¼–ç ç»“æ„ï¼‰ï¼› æˆ–é€šè¿‡ multimodal projector ä¸ LLM çš„æŒ‡ä»¤ token å¹³å‡è¡¨ç¤ºã€‚ è®¡ç®—æ¯ä¸ªè§†è§‰ token ä¸ instruction çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼š\n$$ r_i = \\frac{H^v_i \\cdot \\bar{H}_q}{|H^v_i| , |\\bar{H}_q|} $$\nå¯¹ç›¸å…³æ€§è¿›è¡Œ minâ€“max å½’ä¸€åŒ–ï¼š\n$$ \\tilde{r}_i = \\frac{r_i - \\min(r)}{\\max(r) - \\min(r)} $$\nå¾—åˆ°çš„å‘é‡ ( $\\tilde{r} \\in [0,1]^n$ ) åæ˜ äº†å„è§†è§‰ token å¯¹å½“å‰æŒ‡ä»¤çš„é‡è¦ç¨‹åº¦ã€‚\nç›´è§‚ç†è§£ï¼š\nè¿™ä½¿å¾—å‰ªæå¯ä»¥æ ¹æ®ç”¨æˆ·é—®é¢˜åŠ¨æ€è°ƒæ•´ä¿ç•™åŒºåŸŸã€‚ä¾‹å¦‚ï¼ŒåŒä¸€å¼ å›¾ç‰‡åœ¨ä¸åŒé—®é¢˜ä¸‹ï¼Œå…³æ³¨åŒºåŸŸï¼ˆå³é«˜ ( $\\tilde{r}_i$ )ï¼‰å®Œå…¨ä¸åŒã€‚è®ºæ–‡åœ¨ Figure 3 ä¸­å±•ç¤ºäº†è¿™ç§å¯è§†åŒ–ç»“æœã€‚\nCDPruner æ ¸å¿ƒæœºåˆ¶ï¼šæ¡ä»¶ DPPï¼ˆConditional DPPï¼‰\nä¸ºäº†è”åˆè€ƒè™‘è§†è§‰ç‰¹å¾å¤šæ ·æ€§ä¸æŒ‡ä»¤ç›¸å…³æ€§ï¼ŒCDPruner æ„å»ºäº†æ¡ä»¶æ ¸çŸ©é˜µï¼š\n$$ \\tilde{L} = \\operatorname{diag}(\\tilde{r}) , L , \\operatorname{diag}(\\tilde{r}) $$\nDPP çš„ç›®æ ‡å˜ä¸ºæœ€å¤§åŒ–è¯¥æ ¸çŸ©é˜µçš„è¡Œåˆ—å¼ï¼š\n$$ S^* = \\arg\\max_{S \\subset Z, |S| = m} \\det(\\tilde{L}_S) $$\né€šè¿‡å¯¹æ•°å½¢å¼å¯ä»¥åˆ†è§£ä¸ºï¼š\n$$ \\log\\det(\\tilde{L}S) = \\sum{i \\in S} \\log(\\tilde{r}_i^2) + \\log\\det(L_S) $$\nè¿™æ¸…æ¥šåœ°è¡¨æ˜ï¼ŒCDPruner åŒæ—¶ä¼˜åŒ–ä¸¤é¡¹ï¼š\nrelevance termï¼ˆæŒ‡ä»¤ç›¸å…³æ€§ï¼‰ diversity termï¼ˆå…¨å±€å¤šæ ·æ€§ï¼‰ MAP æ¨æ–­ä¸é«˜æ•ˆè¿‘ä¼¼\nDPP çš„ MAP inference æ˜¯ NP-hard çš„ï¼Œå› æ­¤è®ºæ–‡é‡‡ç”¨äº† è´ªå¿ƒè¿‘ä¼¼ï¼ˆFast Greedy MAPï¼‰ ç®—æ³•ï¼š\nåˆå§‹åŒ–ç©ºé›†åˆ ( S = \\emptyset )ï¼› æ¯æ¬¡è¿­ä»£é€‰å–èƒ½æœ€å¤§åŒ–å½“å‰å¢ç›Šï¼ˆå³è¡Œåˆ—å¼å¢åŠ é‡ï¼‰çš„ tokenï¼› ä½¿ç”¨ Cholesky åˆ†è§£å¿«é€Ÿè®¡ç®—å¢ç›Šï¼Œä»è€Œå®ç°é«˜æ•ˆè¿‘ä¼¼ã€‚ è¯¥ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š\n$$ O(nm^2) $$\nåœ¨å®è·µä¸­ï¼Œå½“ä¿ç•™ token æ•° ( m \\ll n ) æ—¶ï¼Œé¢å¤–å»¶è¿Ÿä»…çº¦ \u003c10ms/sampleï¼Œå¯ç›´æ¥åº”ç”¨äº MLLM æ¨ç†æµç¨‹ä¸­ã€‚\nå¯è°ƒæƒé‡ï¼ˆå¹³è¡¡é¡¹ï¼‰\nè®ºæ–‡è¿˜æå‡ºå¯é€‰å¹³è¡¡å› å­ ( \\theta )ï¼Œç”¨äºæ§åˆ¶ç›¸å…³æ€§ä¸å¤šæ ·æ€§ä¹‹é—´çš„æƒé‡ï¼š\n$$ \\log\\det(\\tilde{L}S) = \\theta \\sum{i \\in S} \\tilde{r}_i + (1 - \\theta) \\log\\det(L_S) $$\nå®éªŒæ˜¾ç¤ºåœ¨ä¸åŒä»»åŠ¡ä¸Šæœ€ä¼˜çš„ ( $\\theta$ ) ä¸åŒï¼Œä¸ºæ¨¡å‹æä¾›äº†æ›´å¥½çš„çµæ´»æ€§ã€‚\nImplementation \u0026 Model-agnostic ç‰¹æ€§\nå¯¹ä¸åŒæ¶æ„å‡å¯ç”¨ï¼ˆLLaVAã€Qwen2.5-VL ç­‰ï¼‰ï¼› è‹¥æ¨¡å‹å…·å¤‡ CLIP-like åŒç¼–ç ç»“æ„ï¼Œç›´æ¥ä½¿ç”¨ text encoder çš„è¾“å‡ºï¼› å¦åˆ™é€šè¿‡ multimodal projector + LLM çš„ instruction token å¹³å‡å¾—åˆ°æ–‡æœ¬è¡¨ç¤ºï¼› å®Œå…¨ training-freeï¼Œå¯ç›´æ¥åµŒå…¥æ¨ç†æµç¨‹ä½œä¸ºæ¨¡å—ã€‚ Evaluations Main Results åœ¨å¤šç§è§†è§‰è¯­è¨€åŸºå‡†ä¸Šï¼ŒCDPruner åœ¨ä¸åŒ token å‰Šå‡ç‡ä¸‹å‡è¶…è¿‡å·²æœ‰æ–¹æ³•ã€‚\nCDPruner for High-resolution Inputs å¯¹é«˜åˆ†è¾¨ç‡è¾“å…¥ï¼ˆå¦‚ LLaVA-NeXT-7B, 2880â†’320 tokensï¼‰ï¼ŒCDPruner æ˜¾è‘—å‡å°‘ FLOPs ä¸å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ã€‚\nCDPruner for Video Understanding \u0026 Advanced Architectures åœ¨è§†é¢‘ä»»åŠ¡ä¸å…ˆè¿›æ¶æ„ï¼ˆå¦‚ Qwen2.5-VLï¼‰ä¸Šï¼ŒCDPruner ä»èƒ½åœ¨ä¸åŒå‹ç¼©ç‡ä¸‹å–å¾—ä¸€è‡´æå‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„é€šç”¨æ€§ä¸å¯è¿ç§»æ€§ã€‚\nEfficiency Analysis \u0026 Ablation Study è®ºæ–‡çš„æ•ˆç‡å®éªŒï¼ˆä»¥ LLaVA-NeXT-7B ä¸ºä¾‹ï¼‰æ˜¾ç¤ºï¼š\nFLOPs å‡å°‘çº¦ 10Ã—ï¼› Prefill latencyã€Decode latency æ˜¾è‘—ä¸‹é™ï¼› GPU memory ä¸ KV cache size å¤§å¹…é™ä½ï¼› ä»…åœ¨æé«˜å‰ªæç‡ä¸‹æ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚ Ablation ç ”ç©¶è¡¨æ˜ï¼š\nåŒæ—¶è€ƒè™‘ conditional relevance ä¸ DPP å¤šæ ·æ€§å¸¦æ¥æœ€ä½³æ€§èƒ½ï¼› ä»…ä½¿ç”¨ attention æˆ– similarity çš„å˜ä½“å‡ä½äº CDPrunerã€‚ Conclusions æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª è®­ç»ƒæ— å…³ã€æ¨¡å‹æ— å…³ çš„è§†è§‰ token å‰ªææ–¹æ³• CDPrunerï¼Œé€šè¿‡å®šä¹‰åŸºäºæŒ‡ä»¤çš„æ¡ä»¶ç›¸ä¼¼æ€§ï¼Œå¹¶ä»¥ DPP å½¢å¼æœ€å¤§åŒ–é€‰ä¸­ token çš„æ¡ä»¶å¤šæ ·æ€§ï¼Œå®ç°äº†æ¨ç†åŠ é€Ÿä¸æ€§èƒ½ä¿æŒçš„ç»Ÿä¸€ã€‚\nCDPruner åœ¨å¤šç§ MLLM æ¶æ„ï¼ˆå¦‚ LLaVA ç³»åˆ—ä¸ Qwen2.5-VLï¼‰ä¸Šå®ç° SOTA æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½å»¶è¿Ÿä¸æ˜¾å­˜ä½¿ç”¨ï¼Œå±•ç°å‡ºåœ¨çœŸå®åº”ç”¨ä¸­éƒ¨ç½²å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ½œåŠ›ã€‚\n",
  "wordCount" : "650",
  "inLanguage": "zh-cn",
  "datePublished": "2025-10-24T00:00:00Z",
  "dateModified": "2025-10-24T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "JJ's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://jjl357.github.io/blog/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
  <nav class="nav">
    <div class="logo">
      
      <a href="https://jjl357.github.io/" accesskey="h" title="ğŸ¥› â˜• ğŸµ (Alt + H)">
        <span>ğŸ¥› â˜• ğŸµ</span>
        
      </a>

      <div class="logo-switches">
        <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
          <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
          <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
        </button>
      </div>
    </div>
    <ul id="menu">
    </ul>
  </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs
    </h1>
    <div class="post-meta"><span title='2025-10-24 00:00:00 +0000 UTC'>October 24, 2025</span>

</div>
  </header> 
  <div class="post-content"><p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/title.png"></p>
<p><strong>Conference</strong>: <strong>NeurIPS'25</strong>
<strong>github</strong>: <a href="https://github.com/Theia-4869/CDPruner">https://github.com/Theia-4869/CDPruner</a></p>
<hr>
<h2 id="my-thoughts">My Thoughts<a hidden class="anchor" aria-hidden="true" href="#my-thoughts">#</a></h2>
<p>ç›¸è¾ƒäº Attention-based methods ä¸­çš„ <strong>attention shift</strong> é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» <strong>å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰</strong> çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† <strong>CDPruner</strong>ï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚</p>
<hr>
<h2 id="motivations">Motivations<a hidden class="anchor" aria-hidden="true" href="#motivations">#</a></h2>
<p>åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š</p>
<ul>
<li>LLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º <strong>576 tokens</strong>ï¼›</li>
<li>LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ <strong>2,880 tokens</strong>ï¼›</li>
<li>LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ <strong>200K visual tokens</strong>ï¼›</li>
<li>LongVILA èƒ½å¤„ç† <strong>6,000 å¸§</strong>å¹¶äº§ç”Ÿ <strong>è¶…è¿‡ 1M visual tokens</strong>ï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚</li>
</ul>
<hr>
<h2 id="challenges">Challenges<a hidden class="anchor" aria-hidden="true" href="#challenges">#</a></h2>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/figure1.png"></p>
<p>ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š</p>
<ol>
<li><strong>Attention-based pruning</strong>ï¼šåˆ©ç”¨ text-visual attention åˆ†æ•°è¡¡é‡è§†è§‰ token çš„é‡è¦æ€§ã€‚</li>
<li><strong>Similarity-based pruning</strong>ï¼šä¾æ®è§†è§‰ token é—´çš„ç›¸ä¼¼æ€§ç§»é™¤å†—ä½™éƒ¨åˆ†ã€‚</li>
</ol>
<p>ç„¶è€Œï¼Œè¿™ä¸¤ç§æ–¹æ³•å‡å­˜åœ¨å›ºæœ‰ç¼ºé™·ã€‚Attention-based æ–¹æ³•åªè€ƒè™‘é‡è¦æ€§ï¼Œå®¹æ˜“ä¿ç•™å¤§é‡é‡å¤ tokenï¼›Similarity-based æ–¹æ³•å¿½ç•¥äº†æŒ‡ä»¤ï¼ˆinstructionï¼‰çš„å…³è”æ€§ï¼Œå¯¼è‡´æ— æ³•é’ˆå¯¹é—®é¢˜è¿›è¡ŒåŠ¨æ€å‰ªæï¼Œä»è€Œæ€§èƒ½æ¬¡ä¼˜ã€‚</p>
<blockquote>
<p>â€œHowever, as pointed out by Zhang et al. [2024b] and Wen et al. [2025a], such methods suffer from <strong>attention shift</strong>, which compromises pruning accuracy.â€</p>
</blockquote>
<h3 id="-ä»€ä¹ˆæ˜¯-attention-shift">âš  ä»€ä¹ˆæ˜¯ attention shiftï¼Ÿ<a hidden class="anchor" aria-hidden="true" href="#-ä»€ä¹ˆæ˜¯-attention-shift">#</a></h3>
<p>(gptå›ç­” ä¸ä¸€å®šæ­£ç¡®)</p>
<p>Attention shift æŒ‡åœ¨ token å‰ªææˆ–è¾“å…¥å˜åŒ–åï¼Œæ¨¡å‹çš„æ³¨æ„åŠ›åˆ†å¸ƒå‘ç”Ÿåç§»ï¼Œå¯¼è‡´åŸæœ¬é‡è¦çš„ token è¢«ä½ä¼°æˆ–ä¿¡æ¯ä¸¢å¤±ï¼Œä»è€Œé™ä½å‰ªæå‡†ç¡®æ€§ã€‚ç”±äº Transformer çš„ self-attention æ˜¯å…¨å±€ä¾èµ–çš„ï¼Œåˆ é™¤éƒ¨åˆ† token ä¼šæ”¹å˜ query-key åˆ†å¸ƒï¼Œä½¿å‰©ä½™ token çš„æ³¨æ„åŠ›é‡æ–°åˆ†å¸ƒï¼Œå¦‚æœä¸è€ƒè™‘è¿™ç§ shiftï¼ŒåŸºäºæ³¨æ„åŠ›çš„å‰ªææ–¹æ³•å®¹æ˜“å‡ºç°å†³ç­–å¤±çœŸï¼Œä¿ç•™é‡å¤ token æˆ–é—æ¼å…³é”® tokenï¼Œä»è€Œå½±å“æ¨ç†æ€§èƒ½ã€‚(<strong>Zhang et al., 2024b, â€œ[CLS] Attention Is All You Need for Training-Free Visual Token Pruning: Make VLM Inference Fasterâ€; Wen et al., 2025a, â€œToken Pruning in Multimodal Large Language Models: Are We Solving the Right Problem?â€</strong>)</p>
<h3 id="-attention-based-æ–¹æ³•ä¸å…¼å®¹é«˜æ•ˆå®ç°å¦‚-flashattention">âš  attention-based æ–¹æ³•ä¸å…¼å®¹é«˜æ•ˆå®ç°å¦‚ FlashAttention<a hidden class="anchor" aria-hidden="true" href="#-attention-based-æ–¹æ³•ä¸å…¼å®¹é«˜æ•ˆå®ç°å¦‚-flashattention">#</a></h3>
<p>æ­¤å¤–ï¼Œattention-based æ–¹æ³•è¿˜ä¾èµ–æ˜¾å¼ attention æƒé‡ï¼Œä¸å…¼å®¹é«˜æ•ˆå®ç°å¦‚ FlashAttentionã€‚</p>
<blockquote>
<p>å› ä¸ºattention-based æ–¹æ³•ä¾èµ–æ˜¾å¼çš„ <strong>attention æƒé‡çŸ©é˜µï¼ˆattention mapï¼‰</strong> æ¥è¯„ä¼°æ¯ä¸ªè§†è§‰ token çš„é‡è¦æ€§ï¼Œéœ€è¦åœ¨æ¨ç†è¿‡ç¨‹ä¸­è®¿é—®å®Œæ•´çš„ Softmax(QKáµ€) ç»“æœæˆ–å…¶ä¸­çš„è¡Œå‘é‡ã€‚ä½†é«˜æ•ˆæ³¨æ„åŠ›å®ç°ï¼ˆå¦‚ <strong>FlashAttention</strong>ï¼‰çš„æ ¸å¿ƒæ€æƒ³æ­£æ˜¯<strong>é¿å…æ˜¾å¼æ„å»ºä¸å­˜å‚¨æ•´ä¸ªæ³¨æ„åŠ›çŸ©é˜µ</strong>ã€‚</p>
<p>FlashAttention å°†æ³¨æ„åŠ›è®¡ç®—åˆ†å—ï¼ˆblock-wiseï¼‰æ‰§è¡Œï¼Œé€šè¿‡åœ¨ GPU çš„é«˜é€Ÿå¯„å­˜å™¨å’Œç‰‡ä¸Š SRAM ä¸­å³æ—¶è®¡ç®— <code>Softmax(QKáµ€)V</code>ï¼Œå¹¶åœ¨æ¯ä¸ªå—ç»“æŸåç«‹åˆ»ä¸¢å¼ƒä¸­é—´çš„ QKáµ€ ç»“æœä¸æ³¨æ„åŠ›æƒé‡ï¼Œä»…ä¿ç•™æœ€ç»ˆè¾“å‡ºã€‚è¿™ç§æ–¹æ³•æå¤§é™ä½äº†æ˜¾å­˜è¯»å†™å’Œå¸¦å®½å ç”¨ï¼Œä½¿å¾—æ³¨æ„åŠ›è®¡ç®—çš„å¤æ‚åº¦ä»å†…å­˜ç“¶é¢ˆï¼ˆmemory-boundï¼‰å˜ä¸ºè®¡ç®—å—é™ï¼ˆcompute-boundï¼‰ï¼Œä»è€Œå®ç°é«˜æ•ˆæ¨ç†ã€‚</p>
<p>ç„¶è€Œï¼Œè¿™ç§å®ç°æ–¹å¼å¸¦æ¥ä¸‰ä¸ªå…³é”®åæœï¼Œä½¿ <strong>attention-based pruning ä¸ FlashAttention ä¸å…¼å®¹</strong>ï¼š</p>
<ol>
<li><strong>ä¸å¯è®¿é—®æ€§</strong>ï¼šFlashAttention ä¸æ˜¾å¼å­˜å‚¨æˆ–è¿”å›å®Œæ•´çš„ attention mapï¼Œå› æ­¤æ— æ³•ç›´æ¥æå–æ¯ä¸ª token çš„æ³¨æ„åŠ›æƒé‡ï¼›è€Œ attention-based æ–¹æ³•æ°æ°éœ€è¦è¿™äº›åˆ†æ•°æ¥åˆ¤æ–­ä¿ç•™ä¸åˆ é™¤ã€‚</li>
<li><strong>å­˜å‚¨ä¸æ€§èƒ½å†²çª</strong>ï¼šè‹¥å¼ºè¡Œä¿®æ”¹ FlashAttention ä»¥è¾“å‡º attention mapï¼Œå°±å¿…é¡»é‡æ–°æ˜¾å¼è®¡ç®—å¹¶ç¼“å­˜ QKáµ€ å’Œ Softmax ç»“æœï¼Œè¿™ä¼šç ´åå…¶å†…å­˜å¤ç”¨æœºåˆ¶ï¼Œé‡æ–°å¼•å…¥å¤§è§„æ¨¡å†…å­˜è®¿é—®ä¸æ˜¾å­˜å ç”¨ï¼Œæ€§èƒ½æ€¥å‰§ä¸‹é™ã€‚</li>
<li><strong>å¤šå¤´ä¸å±‚æ¬¡ä¸ç¨³å®šæ€§</strong>ï¼šä¸åŒå±‚ã€ä¸åŒå¤´çš„æ³¨æ„åŠ›æƒé‡åˆ†å¸ƒå·®å¼‚æ˜¾è‘—ï¼Œä¸” FlashAttention å†…éƒ¨æŒ‰å—ç´¯ç§¯ Softmaxï¼Œä¼šè¿›ä¸€æ­¥å¯¼è‡´ attention å€¼åœ¨ä¸åŒåˆ†å—é—´ä¸å¯ç›´æ¥æ¯”è¾ƒï¼Œå¢åŠ äº†åŸºäº attention å€¼è¿›è¡Œç»Ÿä¸€æ’åºå’Œå‰ªæçš„éš¾åº¦ã€‚</li>
</ol>
<p>å› æ­¤ï¼Œåœ¨é‡‡ç”¨ FlashAttention æˆ–å…¶ä»–é«˜æ•ˆæ³¨æ„åŠ›ä¼˜åŒ–ï¼ˆå¦‚ xFormersã€PagedAttentionï¼‰çš„ç°ä»£ MLLM ä¸­ï¼Œ<strong>attention-based pruning æ–¹æ³•æ— æ³•ç›´æ¥ä½¿ç”¨æˆ–ä¼šç ´åæ¨ç†åŠ é€Ÿæ•ˆæœ</strong>ã€‚</p>
</blockquote>
<p>å› æ­¤ï¼Œä½œè€…æå‡ºä» â€œbeyond attention or similarityâ€ çš„è§’åº¦é‡æ–°æ€è€ƒ token pruningã€‚</p>
<hr>
<h2 id="contributions">Contributions<a hidden class="anchor" aria-hidden="true" href="#contributions">#</a></h2>
<ol>
<li>æå‡º <strong>CDPruner</strong>ï¼šä¸€ç§ plug-and-playã€model-agnostic çš„è§†è§‰ token å‰ªææ–¹æ¡ˆï¼Œé€šè¿‡æœ€å¤§åŒ–æ¡ä»¶å¤šæ ·æ€§ï¼ˆconditional diversityï¼‰å®ç°é«˜æ•ˆåŠ¨æ€å‰ªæï¼›</li>
<li>å°† token pruning é—®é¢˜é‡æ„ä¸º <strong>DPPï¼ˆDeterminantal Point Processï¼‰</strong>ï¼Œè”åˆè€ƒè™‘ feature similarity ä¸ instruction relevanceï¼›</li>
<li>åœ¨å¤šç§è§†è§‰è¯­è¨€åŸºå‡†ä¸Šå®éªŒéªŒè¯ï¼ŒCDPruner åœ¨ä¸åŒå‹ç¼©ç‡ä¸‹å‡å–å¾— SOTAã€‚</li>
</ol>
<hr>
<h2 id="methods">Methods<a hidden class="anchor" aria-hidden="true" href="#methods">#</a></h2>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/figure2.png"></p>
<h3 id="determinantal-point-process-dpp">Determinantal Point Process (DPP)<a hidden class="anchor" aria-hidden="true" href="#determinantal-point-process-dpp">#</a></h3>
<p>DPP æœ€åˆç”¨äºåˆ»ç”»è´¹ç±³å­ç³»ç»Ÿçš„â€œæ’æ–¥æ•ˆåº”â€ï¼Œåœ¨æœºå™¨å­¦ä¹ ä¸­è¢«å¹¿æ³›ç”¨äºå»ºæ¨¡é›†åˆé€‰æ‹©çš„<strong>å…¨å±€å¤šæ ·æ€§</strong>ã€‚</p>
<p>ä¸ Max-Min Diversity Problem (MMDP) ä»…å…³æ³¨æç«¯æ ·æœ¬ä¸åŒï¼ŒDPP å¼ºè°ƒå…¨å±€å¹³è¡¡å’Œä»£è¡¨æ€§ã€‚ä¼ ç»Ÿ DPP ä»…è€ƒè™‘æ ·æœ¬é—´ç›¸ä¼¼åº¦ï¼Œè€Œæœ¬è®ºæ–‡åœ¨æ­¤åŸºç¡€ä¸Šå¼•å…¥ instruction relevanceï¼Œä½¿å‰ªæè¿‡ç¨‹åŒæ—¶è€ƒè™‘â€œtoken ç›¸å…³æ€§â€ä¸â€œå¤šæ ·æ€§â€ã€‚</p>
<hr>
<h3 id="dpp-with-token-similarity">DPP with Token Similarity<a hidden class="anchor" aria-hidden="true" href="#dpp-with-token-similarity">#</a></h3>
<p><strong>æ ¸å¿ƒæ€æƒ³ï¼š</strong>
å°†è§†è§‰ token çš„ pairwise similarity å»ºæ¨¡ä¸ºä¸€ä¸ªæ ¸çŸ©é˜µ ( L )ï¼Œå¹¶é€šè¿‡æœ€å¤§åŒ–å…¶è¡Œåˆ—å¼ï¼ˆdeterminantï¼‰æ¥é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„å­é›†ã€‚</p>
<p>å®šä¹‰æ¯ä¸ªè§†è§‰ token çš„ç‰¹å¾å‘é‡ä¸º ( $H^v_i \in \mathbb{R}^d$ )ï¼Œåˆ™ç›¸ä¼¼æ ¸çŸ©é˜µä¸ºï¼š</p>
<p>$$
L_{ij} = \frac{H^v_i \cdot H^v_j}{|H^v_i| , |H^v_j|}
$$</p>
<p>ç›®æ ‡æ˜¯é€‰æ‹©ä¸€ä¸ªåŒ…å« ( m ) ä¸ª token çš„å­é›† ( $S \subset Z$ )ï¼Œä½¿å¾—ï¼š</p>
<p>$$
S^* = \arg\max_{S \subset Z, |S|=m} \det(L_S)
$$</p>
<p>è¿™é‡Œ ( $L_S$ ) æ˜¯å¯¹åº”å­é›†çš„å­çŸ©é˜µã€‚è¡Œåˆ—å¼è¶Šå¤§ï¼Œä»£è¡¨è¯¥å­é›†åœ¨ç‰¹å¾ç©ºé—´ä¸­â€œè¦†ç›–çš„æ–¹å‘â€è¶Šå¤šï¼Œä¿¡æ¯å†—ä½™è¶Šä½ã€‚</p>
<p><strong>ç›´è§‚è§£é‡Šï¼š</strong>
å¦‚æœä¸¤ä¸ª token çš„ç‰¹å¾éå¸¸ç›¸ä¼¼ï¼ˆçº¿æ€§ç›¸å…³ï¼‰ï¼Œè¡Œåˆ—å¼ä¼šå‡å°ã€‚å› æ­¤ DPP å¤©ç„¶å€¾å‘ä¿ç•™â€œäº’è¡¥â€ä¿¡æ¯è€Œéé‡å¤ tokenï¼Œä»è€Œå®ç°é«˜æ•ˆä¸”å…¨å±€å‡è¡¡çš„å‰ªæã€‚</p>
<hr>
<h3 id="instruction-relevance">Instruction Relevance<a hidden class="anchor" aria-hidden="true" href="#instruction-relevance">#</a></h3>
<p>ä¼ ç»Ÿ DPP ä»…åŸºäºè§†è§‰ç‰¹å¾æ„å»ºæ ¸çŸ©é˜µï¼Œæ— æ³•ä½“ç°è§†è§‰ token ä¸æ–‡æœ¬æŒ‡ä»¤çš„ç›¸å…³æ€§ã€‚CDPruner é€šè¿‡ä»¥ä¸‹æ­¥éª¤å¼•å…¥ <strong>æ¡ä»¶ç›¸å…³æ€§ï¼ˆconditional relevanceï¼‰</strong>ï¼š</p>
<ol>
<li>
<p>è·å–è§†è§‰ token è¡¨ç¤º ( $H_v \in \mathbb{R}^{n \times d}$ )ï¼›</p>
</li>
<li>
<p>è·å–æ–‡æœ¬åµŒå…¥ï¼ˆinstruction embeddingï¼‰ ( $\bar{H}_q \in \mathbb{R}^d $)ï¼Œå…¶æ¥æºå¯ä»¥æ˜¯ï¼š</p>
<ul>
<li>CLIP-like text encoderï¼ˆè‹¥æ¨¡å‹å…·å¤‡åŒç¼–ç ç»“æ„ï¼‰ï¼›</li>
<li>æˆ–é€šè¿‡ multimodal projector ä¸ LLM çš„æŒ‡ä»¤ token å¹³å‡è¡¨ç¤ºã€‚</li>
</ul>
</li>
<li>
<p>è®¡ç®—æ¯ä¸ªè§†è§‰ token ä¸ instruction çš„ä½™å¼¦ç›¸ä¼¼åº¦ï¼š</p>
<p>$$
r_i = \frac{H^v_i \cdot \bar{H}_q}{|H^v_i| , |\bar{H}_q|}
$$</p>
</li>
<li>
<p>å¯¹ç›¸å…³æ€§è¿›è¡Œ minâ€“max å½’ä¸€åŒ–ï¼š</p>
<p>$$
\tilde{r}_i = \frac{r_i - \min(r)}{\max(r) - \min(r)}
$$</p>
</li>
</ol>
<p>å¾—åˆ°çš„å‘é‡ ( $\tilde{r} \in [0,1]^n$ ) åæ˜ äº†å„è§†è§‰ token å¯¹å½“å‰æŒ‡ä»¤çš„é‡è¦ç¨‹åº¦ã€‚</p>
<p><strong>ç›´è§‚ç†è§£ï¼š</strong></p>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/figure3.png"></p>
<p>è¿™ä½¿å¾—å‰ªæå¯ä»¥æ ¹æ®ç”¨æˆ·é—®é¢˜åŠ¨æ€è°ƒæ•´ä¿ç•™åŒºåŸŸã€‚ä¾‹å¦‚ï¼ŒåŒä¸€å¼ å›¾ç‰‡åœ¨ä¸åŒé—®é¢˜ä¸‹ï¼Œå…³æ³¨åŒºåŸŸï¼ˆå³é«˜ ( $\tilde{r}_i$ )ï¼‰å®Œå…¨ä¸åŒã€‚è®ºæ–‡åœ¨ Figure 3 ä¸­å±•ç¤ºäº†è¿™ç§å¯è§†åŒ–ç»“æœã€‚</p>
<hr>
<h3 id="cdpruner">CDPruner<a hidden class="anchor" aria-hidden="true" href="#cdpruner">#</a></h3>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/figure2.png"></p>
<p><strong>æ ¸å¿ƒæœºåˆ¶ï¼šæ¡ä»¶ DPPï¼ˆConditional DPPï¼‰</strong></p>
<p>ä¸ºäº†è”åˆè€ƒè™‘è§†è§‰ç‰¹å¾å¤šæ ·æ€§ä¸æŒ‡ä»¤ç›¸å…³æ€§ï¼ŒCDPruner æ„å»ºäº†æ¡ä»¶æ ¸çŸ©é˜µï¼š</p>
<p>$$
\tilde{L} = \operatorname{diag}(\tilde{r}) , L , \operatorname{diag}(\tilde{r})
$$</p>
<p>DPP çš„ç›®æ ‡å˜ä¸ºæœ€å¤§åŒ–è¯¥æ ¸çŸ©é˜µçš„è¡Œåˆ—å¼ï¼š</p>
<p>$$
S^* = \arg\max_{S \subset Z, |S| = m} \det(\tilde{L}_S)
$$</p>
<p>é€šè¿‡å¯¹æ•°å½¢å¼å¯ä»¥åˆ†è§£ä¸ºï¼š</p>
<p>$$
\log\det(\tilde{L}<em>S) = \sum</em>{i \in S} \log(\tilde{r}_i^2) + \log\det(L_S)
$$</p>
<p>è¿™æ¸…æ¥šåœ°è¡¨æ˜ï¼ŒCDPruner åŒæ—¶ä¼˜åŒ–ä¸¤é¡¹ï¼š</p>
<ul>
<li>relevance termï¼ˆæŒ‡ä»¤ç›¸å…³æ€§ï¼‰</li>
<li>diversity termï¼ˆå…¨å±€å¤šæ ·æ€§ï¼‰</li>
</ul>
<hr>
<p><strong>MAP æ¨æ–­ä¸é«˜æ•ˆè¿‘ä¼¼</strong></p>
<p>DPP çš„ MAP inference æ˜¯ NP-hard çš„ï¼Œå› æ­¤è®ºæ–‡é‡‡ç”¨äº† <strong>è´ªå¿ƒè¿‘ä¼¼ï¼ˆFast Greedy MAPï¼‰</strong> ç®—æ³•ï¼š</p>
<ol>
<li>åˆå§‹åŒ–ç©ºé›†åˆ ( S = \emptyset )ï¼›</li>
<li>æ¯æ¬¡è¿­ä»£é€‰å–èƒ½æœ€å¤§åŒ–å½“å‰å¢ç›Šï¼ˆå³è¡Œåˆ—å¼å¢åŠ é‡ï¼‰çš„ tokenï¼›</li>
<li>ä½¿ç”¨ Cholesky åˆ†è§£å¿«é€Ÿè®¡ç®—å¢ç›Šï¼Œä»è€Œå®ç°é«˜æ•ˆè¿‘ä¼¼ã€‚</li>
</ol>
<p>è¯¥ç®—æ³•çš„æ—¶é—´å¤æ‚åº¦ä¸ºï¼š</p>
<p>$$
O(nm^2)
$$</p>
<p>åœ¨å®è·µä¸­ï¼Œå½“ä¿ç•™ token æ•° ( m \ll n ) æ—¶ï¼Œé¢å¤–å»¶è¿Ÿä»…çº¦ <strong>&lt;10ms/sample</strong>ï¼Œå¯ç›´æ¥åº”ç”¨äº MLLM æ¨ç†æµç¨‹ä¸­ã€‚</p>
<hr>
<p><strong>å¯è°ƒæƒé‡ï¼ˆå¹³è¡¡é¡¹ï¼‰</strong></p>
<p>è®ºæ–‡è¿˜æå‡ºå¯é€‰å¹³è¡¡å› å­ ( \theta )ï¼Œç”¨äºæ§åˆ¶ç›¸å…³æ€§ä¸å¤šæ ·æ€§ä¹‹é—´çš„æƒé‡ï¼š</p>
<p>$$
\log\det(\tilde{L}<em>S) = \theta \sum</em>{i \in S} \tilde{r}_i + (1 - \theta) \log\det(L_S)
$$</p>
<p>å®éªŒæ˜¾ç¤ºåœ¨ä¸åŒä»»åŠ¡ä¸Šæœ€ä¼˜çš„ ( $\theta$ ) ä¸åŒï¼Œä¸ºæ¨¡å‹æä¾›äº†æ›´å¥½çš„çµæ´»æ€§ã€‚</p>
<hr>
<p><strong>Implementation &amp; Model-agnostic ç‰¹æ€§</strong></p>
<ul>
<li>å¯¹ä¸åŒæ¶æ„å‡å¯ç”¨ï¼ˆLLaVAã€Qwen2.5-VL ç­‰ï¼‰ï¼›</li>
<li>è‹¥æ¨¡å‹å…·å¤‡ CLIP-like åŒç¼–ç ç»“æ„ï¼Œç›´æ¥ä½¿ç”¨ text encoder çš„è¾“å‡ºï¼›</li>
<li>å¦åˆ™é€šè¿‡ multimodal projector + LLM çš„ instruction token å¹³å‡å¾—åˆ°æ–‡æœ¬è¡¨ç¤ºï¼›</li>
<li>å®Œå…¨ <strong>training-free</strong>ï¼Œå¯ç›´æ¥åµŒå…¥æ¨ç†æµç¨‹ä½œä¸ºæ¨¡å—ã€‚</li>
</ul>
<hr>
<h2 id="evaluations">Evaluations<a hidden class="anchor" aria-hidden="true" href="#evaluations">#</a></h2>
<h3 id="main-results">Main Results<a hidden class="anchor" aria-hidden="true" href="#main-results">#</a></h3>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/table1.png"></p>
<p>åœ¨å¤šç§è§†è§‰è¯­è¨€åŸºå‡†ä¸Šï¼ŒCDPruner åœ¨ä¸åŒ token å‰Šå‡ç‡ä¸‹å‡è¶…è¿‡å·²æœ‰æ–¹æ³•ã€‚</p>
<hr>
<h3 id="cdpruner-for-high-resolution-inputs">CDPruner for High-resolution Inputs<a hidden class="anchor" aria-hidden="true" href="#cdpruner-for-high-resolution-inputs">#</a></h3>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/table2.png"></p>
<p>å¯¹é«˜åˆ†è¾¨ç‡è¾“å…¥ï¼ˆå¦‚ LLaVA-NeXT-7B, 2880â†’320 tokensï¼‰ï¼ŒCDPruner æ˜¾è‘—å‡å°‘ FLOPs ä¸å»¶è¿Ÿï¼ŒåŒæ—¶ä¿æŒæ€§èƒ½ã€‚</p>
<hr>
<h3 id="cdpruner-for-video-understanding--advanced-architectures">CDPruner for Video Understanding &amp; Advanced Architectures<a hidden class="anchor" aria-hidden="true" href="#cdpruner-for-video-understanding--advanced-architectures">#</a></h3>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/table34.png"></p>
<p>åœ¨è§†é¢‘ä»»åŠ¡ä¸å…ˆè¿›æ¶æ„ï¼ˆå¦‚ Qwen2.5-VLï¼‰ä¸Šï¼ŒCDPruner ä»èƒ½åœ¨ä¸åŒå‹ç¼©ç‡ä¸‹å–å¾—ä¸€è‡´æå‡ï¼ŒéªŒè¯äº†æ–¹æ³•çš„é€šç”¨æ€§ä¸å¯è¿ç§»æ€§ã€‚</p>
<hr>
<h3 id="efficiency-analysis--ablation-study">Efficiency Analysis &amp; Ablation Study<a hidden class="anchor" aria-hidden="true" href="#efficiency-analysis--ablation-study">#</a></h3>
<p><img loading="lazy" src="https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/t5f4.png"></p>
<p>è®ºæ–‡çš„æ•ˆç‡å®éªŒï¼ˆä»¥ LLaVA-NeXT-7B ä¸ºä¾‹ï¼‰æ˜¾ç¤ºï¼š</p>
<ul>
<li><strong>FLOPs</strong> å‡å°‘çº¦ 10Ã—ï¼›</li>
<li><strong>Prefill latency</strong>ã€<strong>Decode latency</strong> æ˜¾è‘—ä¸‹é™ï¼›</li>
<li><strong>GPU memory</strong> ä¸ <strong>KV cache size</strong> å¤§å¹…é™ä½ï¼›</li>
<li>ä»…åœ¨æé«˜å‰ªæç‡ä¸‹æ€§èƒ½ç•¥æœ‰ä¸‹é™ã€‚</li>
</ul>
<p>Ablation ç ”ç©¶è¡¨æ˜ï¼š</p>
<ul>
<li>åŒæ—¶è€ƒè™‘ conditional relevance ä¸ DPP å¤šæ ·æ€§å¸¦æ¥æœ€ä½³æ€§èƒ½ï¼›</li>
<li>ä»…ä½¿ç”¨ attention æˆ– similarity çš„å˜ä½“å‡ä½äº CDPrunerã€‚</li>
</ul>
<hr>
<h2 id="conclusions">Conclusions<a hidden class="anchor" aria-hidden="true" href="#conclusions">#</a></h2>
<p>æœ¬æ–‡æå‡ºäº†ä¸€ä¸ª <strong>è®­ç»ƒæ— å…³ã€æ¨¡å‹æ— å…³</strong> çš„è§†è§‰ token å‰ªææ–¹æ³• <strong>CDPruner</strong>ï¼Œé€šè¿‡å®šä¹‰åŸºäºæŒ‡ä»¤çš„æ¡ä»¶ç›¸ä¼¼æ€§ï¼Œå¹¶ä»¥ DPP å½¢å¼æœ€å¤§åŒ–é€‰ä¸­ token çš„æ¡ä»¶å¤šæ ·æ€§ï¼Œå®ç°äº†æ¨ç†åŠ é€Ÿä¸æ€§èƒ½ä¿æŒçš„ç»Ÿä¸€ã€‚</p>
<p>CDPruner åœ¨å¤šç§ MLLM æ¶æ„ï¼ˆå¦‚ LLaVA ç³»åˆ—ä¸ Qwen2.5-VLï¼‰ä¸Šå®ç° SOTA æ€§èƒ½ï¼ŒåŒæ—¶æ˜¾è‘—é™ä½å»¶è¿Ÿä¸æ˜¾å­˜ä½¿ç”¨ï¼Œå±•ç°å‡ºåœ¨çœŸå®åº”ç”¨ä¸­éƒ¨ç½²å¤šæ¨¡æ€å¤§æ¨¡å‹çš„æ½œåŠ›ã€‚</p>
<hr>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://jjl357.github.io/blog/tags/kv-cache/">KV Cache</a></li>
      <li><a href="https://jjl357.github.io/blog/tags/mllm/">MLLM</a></li>
      <li><a href="https://jjl357.github.io/blog/tags/paper-note/">Paper Note</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://jjl357.github.io/blog/">JJ&#39;s Blog</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
