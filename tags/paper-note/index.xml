<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Paper Note on JJ&#39;s Blog</title>
    <link>https://jjl357.github.io/blog/tags/paper-note/</link>
    <description>Recent content in Paper Note on JJ&#39;s Blog</description>
    <generator>Hugo -- 0.152.2</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 01 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://jjl357.github.io/blog/tags/paper-note/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ada-KV: Optimizing KV Cache Eviction by Adaptive Budget Allocation for Efficient LLM Inference </title>
      <link>https://jjl357.github.io/blog/posts/ada-kv---optimizing-kv-cache-eviction-by-adaptive-budget-allocation-for-efficient-llm-inference---neurips25/</link>
      <pubDate>Sat, 01 Nov 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/ada-kv---optimizing-kv-cache-eviction-by-adaptive-budget-allocation-for-efficient-llm-inference---neurips25/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/AdaKV/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference&lt;/strong&gt;: &lt;strong&gt;NeurIPS&#39;25&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github&lt;/strong&gt;: &lt;a href=&#34;https://github.com/FFY0/AdaKV&#34;&gt;https://github.com/FFY0/AdaKV&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;my-thoughts&#34;&gt;My Thoughts&lt;/h2&gt;
&lt;p&gt;è¿™ç¯‡å·¥ä½œçš„ideaåœ¨å„ä¸ªheadä¹‹é—´adaptive åˆ†é… budget, ç›´è§‰ä¸Šå°±èƒ½çŸ¥é“è¿™ç§è®¾è®¡æ˜¯æœ‰æ•ˆçš„ï¼Œå®éªŒä¹ŸéªŒè¯äº†è¿™ä¸€ç‚¹ã€‚&lt;/p&gt;
&lt;p&gt;æ¯”è¾ƒæƒŠå–œçš„æ˜¯ä½œè€…å®ç°äº†With efficient CUDA kernel implementationsæ¥è§£å†³variable-sized cache elements across attention headsï¼Œä»è€Œæ¥çœŸæ­£å®ç°äº†è®¡ç®—åŠ é€Ÿï¼Œä»¥åŠå…¶ä»–KV Cacheå·¥ä½œåœ¨ä¹Ÿå®ç°äº†å¯¹AdaKVé›†æˆï¼Œå†æ¬¡è¯æ˜äº†å…¶ä½œä¸ºé€šç”¨å¢å¼ºæ¨¡å—çš„ä»·å€¼ã€‚&lt;/p&gt;
&lt;h2 id=&#34;1-motivation&#34;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨å„ä¸ªé¢†åŸŸè¡¨ç°å‡ºè‰²ï¼Œä½†ç”±äºé•¿åºåˆ—æ¨ç†æ‰€éœ€çš„ä¸æ–­å¢é•¿çš„é”®å€¼ï¼ˆKVï¼‰cacheï¼Œé¢ä¸´ç€æ•ˆç‡æŒ‘æˆ˜ã€‚LLM çš„å¹¿æ³›åº”ç”¨æ¨åŠ¨äº†å…¶å¤„ç†æ‰©å±•åºåˆ—èƒ½åŠ›çš„å‘å±•ã€‚ä¾‹å¦‚ï¼ŒGPT æ”¯æŒé•¿è¾¾ 128K çš„åºåˆ—ï¼ŒClaude3 æ”¯æŒ 200Kï¼ŒGemini-Pro-1.5 ç”šè‡³æ”¯æŒé«˜è¾¾ 2M ä¸ª tokenã€‚ç„¶è€Œï¼Œè¿™ç§ token é•¿åº¦çš„å¢é•¿å¸¦æ¥äº†æ˜¾è‘—çš„æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ¨ç†è¿‡ç¨‹ä¸­cacheå¤§å°çš„æ€¥å‰§è†¨èƒ€ã€‚å¯¹äºä¸€ä¸ª 8B çš„ LLMï¼Œå¤„ç†ä¸€ä¸ª 2M token çš„åºåˆ—å¯èƒ½éœ€è¦é«˜è¾¾ 256GB çš„cacheï¼Œè¿™ä¸¥é‡å½±å“äº† GPU å†…å­˜æ•ˆç‡å’Œè®¡ç®—è¿è¡Œæ—¶æ•ˆç‡ã€‚&lt;/p&gt;
&lt;p&gt;ç°æœ‰çš„ KV cacheé©±é€æ–¹æ³•é€šå¸¸åœ¨æ‰€æœ‰æ³¨æ„åŠ›headä¸Š&lt;strong&gt;å‡åŒ€åˆ†é…&lt;/strong&gt;å‹ç¼©é¢„ç®—ï¼Œå¿½ç•¥äº†æ¯ä¸ªheadç‹¬ç‰¹çš„æ³¨æ„åŠ›æ¨¡å¼ã€‚å¦‚ &lt;strong&gt;Figure 1a&lt;/strong&gt; æ‰€ç¤ºï¼Œä¸åŒheadçš„æ³¨æ„åŠ›é›†ä¸­åº¦ï¼ˆconcentrationï¼‰å·®å¼‚å·¨å¤§ï¼šä¸€äº›headï¼ˆsparse headsï¼‰çš„æ³¨æ„åŠ›é«˜åº¦é›†ä¸­åœ¨å°‘æ•°å‡ ä¸ª token ä¸Šï¼Œè€Œå¦ä¸€äº›headï¼ˆdispersed headsï¼‰çš„æ³¨æ„åŠ›åˆ™åˆ†å¸ƒå¾—æ›´å¹¿ã€‚è¿™ç§å‡åŒ€åˆ†é…å¯¼è‡´äº†æ•ˆç‡ä½ä¸‹â€”â€”è¦ä¹ˆåœ¨ç¨€ç–é›†ä¸­çš„headä¸Šæµªè´¹cacheé¢„ç®—ï¼Œè¦ä¹ˆåœ¨åˆ†æ•£åˆ†å¸ƒçš„headä¸Šé€ æˆæ˜¾è‘—çš„é©±é€æŸå¤±ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/AdaKV/figure1.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;2-relative-work&#34;&gt;2. Relative Work&lt;/h2&gt;
&lt;h3 id=&#34;21-cache-eviction-methods&#34;&gt;2.1 Cache Eviction Methods&lt;/h3&gt;
&lt;p&gt;cacheé©±é€æ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼šæ»‘åŠ¨çª—å£é©±é€å’Œ Top-k é©±é€ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;æ»‘åŠ¨çª—å£æ–¹æ³•&lt;/strong&gt;ï¼ˆå¦‚ StreamingLLMï¼‰ç®€å•åœ°ä¿ç•™åˆå§‹cacheå…ƒç´ å’Œæ»‘åŠ¨çª—å£å†…çš„å…ƒç´ ï¼Œä½†è¿™ç§æ— å·®åˆ«çš„é©±é€ä¼šæ˜¾è‘—é™ä½ç”Ÿæˆè´¨é‡ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Top-k é©±é€æ–¹æ³•&lt;/strong&gt;ï¼ˆå¦‚ H2O, SnapKV, Pyramidï¼‰åŸºäºæ³¨æ„åŠ›æƒé‡è¯†åˆ«å¹¶ä¿ç•™ &lt;code&gt;k&lt;/code&gt; ä¸ªå…³é”®cacheå…ƒç´ ã€‚ç„¶è€Œï¼Œç°æœ‰ Top-k æ–¹æ³•é€šå¸¸åœ¨ä¸åŒheadä¸Š&lt;strong&gt;å‡åŒ€åˆ†é…&lt;/strong&gt;æ€»é¢„ç®—ã€‚Ada-KV é€šè¿‡&lt;strong&gt;è‡ªé€‚åº”é¢„ç®—åˆ†é…&lt;/strong&gt;æ¥å¢å¼ºè¿™äº›æ–¹æ³•ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;22-sparse-attention-methods&#34;&gt;2.2 Sparse Attention Methods&lt;/h3&gt;
&lt;p&gt;ç¨€ç–æ³¨æ„åŠ›æ–¹æ³•ä¸ KV cacheé©±é€åœ¨æ ¹æœ¬ä¸Šä¸åŒï¼šå‰è€…ä¿ç•™æ‰€æœ‰cacheï¼Œä½†åœ¨è®¡ç®—æ—¶åªé€‰æ‹©æ€§åœ°ä½¿ç”¨å…³é”®å­é›†ï¼Œå› æ­¤&lt;strong&gt;ä¸å‡å°‘å†…å­˜å ç”¨&lt;/strong&gt;ã€‚è€Œ KV cacheé©±é€ç›´æ¥ç§»é™¤éå…³é”®æ¡ç›®ï¼Œä»è€Œå‡å°å†…å­˜å ç”¨ã€‚è¿™ä¸¤ç§æŠ€æœ¯æ˜¯æ­£orthogonalçš„ï¼Œæœªæ¥å¯ä»¥ç»“åˆä½¿ç”¨ã€‚&lt;/p&gt;</description>
    </item>
    <item>
      <title>NOT ALL HEADS MATTER: A HEAD-LEVEL KV CACHE COMPRESSION METHOD WITH INTEGRATED RETRIEVAL AND REASONING</title>
      <link>https://jjl357.github.io/blog/posts/not-all-heads-matter---a-head-level-kv-cache-compression-method-with-integrated-retrieval-and-reasoning---iclr25/</link>
      <pubDate>Fri, 31 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/not-all-heads-matter---a-head-level-kv-cache-compression-method-with-integrated-retrieval-and-reasoning---iclr25/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/HeadKV/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference:&lt;/strong&gt; ICLR&#39;25&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github:&lt;/strong&gt; &lt;a href=&#34;https://github.com/FYYFU/HeadKV&#34;&gt;https://github.com/FYYFU/HeadKV&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;my-thoughts&#34;&gt;My Thoughts&lt;/h2&gt;
&lt;p&gt;è¿™ç¯‡å·¥ä½œå’Œ DuoAttention çš„å…³æ³¨ç‚¹ç±»ä¼¼ï¼Œéƒ½æ˜¯å…³æ³¨ä¸åŒ attention head å¯¹æ¨¡å‹ä¸åŒèƒ½åŠ›çš„è´¡çŒ®ä¸åŒï¼Œè¿™ç¯‡å·¥ä½œæ›´å…³æ³¨ attention head å¯¹æ¨¡å‹ &lt;strong&gt;Retrieval&lt;/strong&gt; ä¸ &lt;strong&gt;Reasoning&lt;/strong&gt; çš„ importance score, æ¥å®ç° KV Cache çš„ nonuniform budget allocation ã€‚&lt;/p&gt;
&lt;h2 id=&#34;1-motivation&#34;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;ç°ä»£ LLM è¶Šæ¥è¶Šæ”¯æŒæé•¿ä¸Šä¸‹æ–‡ï¼ˆä¾‹å¦‚ GPT-4ã€Llama-3ã€Qwen-2ã€Claude ç­‰ï¼‰ï¼Œä½†éšç€è¾“å…¥é•¿åº¦å¢é•¿ï¼ŒTransformer çš„ self-attention å¯¼è‡´ KV cacheï¼ˆattention çš„ key/value çŠ¶æ€ï¼‰å ç”¨å†…å­˜çº¿æ€§å¢é•¿ï¼Œæˆä¸ºæ¨ç†é˜¶æ®µçš„ä¸»è¦ç“¶é¢ˆã€‚å·²æœ‰å·¥ä½œé€šè¿‡ token eviction / å±‚çº§ç¼“å­˜å‹ç¼©æ¥ç¼“è§£ï¼Œä½†&lt;strong&gt;å‡ ä¹æ²¡æœ‰ç ”ç©¶åœ¨â€œå¤´ï¼ˆheadï¼‰çº§åˆ«â€ä¸Šå¯¹ KV cache å¤§å°è¿›è¡Œå·®å¼‚åŒ–åˆ†é…&lt;/strong&gt;ã€‚ä½œè€…è§‚å¯Ÿåˆ° attention heads åœ¨åŠŸèƒ½ä¸Šé«˜åº¦å¼‚è´¨ï¼ˆå¦‚ retrieval headsã€reasoning heads ç­‰ï¼‰ï¼Œå› æ­¤æå‡ºåŸºäºå¤´é‡è¦æ€§çš„ head-level KV cache å‹ç¼©æ–¹æ³•ï¼ˆHeadKVï¼‰ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šæå‡ºç»“åˆæ£€ç´¢ä¸æ¨ç†èƒ½åŠ›è¯„ä¼°çš„ HeadKV-R2ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-relative-work&#34;&gt;2. Relative Work&lt;/h2&gt;
&lt;h3 id=&#34;21-attention-heads&#34;&gt;2.1 Attention heads&lt;/h3&gt;
&lt;p&gt;å›é¡¾äº†å¯¹å¤šå¤´æ³¨æ„åŠ›ä¸­ head åŠŸèƒ½çš„ç ”ç©¶ï¼ˆVoita et al., Olsson et al., Wu et al., Zheng et al. ç­‰ï¼‰ï¼Œå¹¶æŒ‡å‡ºä¸åŒ head åœ¨è¯æ³•ã€ç»“æ„ã€å¤åˆ¶ï¼ˆinductionï¼‰ã€æ£€ç´¢ç­‰æ–¹é¢æ‰®æ¼”ä¸åŒè§’è‰²ã€‚è¿™äº›è§‚å¯Ÿä¸ºæŒ‰ head åˆ†é… KV cache æä¾›ç†è®ºåŸºç¡€ã€‚&lt;/p&gt;</description>
    </item>
    <item>
      <title>QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models</title>
      <link>https://jjl357.github.io/blog/posts/qsvd----efficient-low-rank-approximation-for-unified-query-key-value-weight-compression-in-low-precision-vision-language-models---neurips25-spotlight/</link>
      <pubDate>Thu, 30 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/qsvd----efficient-low-rank-approximation-for-unified-query-key-value-weight-compression-in-low-precision-vision-language-models---neurips25-spotlight/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/QSVD/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference:&lt;/strong&gt; NeurIPS&#39;25 Spotlight&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github:&lt;/strong&gt; &lt;a href=&#34;https://github.com/SAI-Lab-NYU/QSVD&#34;&gt;https://github.com/SAI-Lab-NYU/QSVD&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-motivation&#34;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;Visionâ€“Language Models (VLMs) å¦‚ LLaVAã€BLIP2 ç­‰åœ¨å›¾åƒæè¿°ã€è§†è§‰é—®ç­” (VQA) ç­‰ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œä½†è¿™äº›æ¨¡å‹éœ€è¦æå¤§çš„è®¡ç®—ä¸å­˜å‚¨å¼€é”€ï¼Œå°¤å…¶åœ¨æ¨ç†æ—¶ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;KV Cache å ç”¨é«˜&lt;/strong&gt;ï¼šæ³¨æ„åŠ›æœºåˆ¶ä¸­éœ€å­˜å‚¨ Keyã€Valueï¼Œæ¯å±‚ç¼“å­˜å¤§å°éšåºåˆ—é•¿åº¦çº¿æ€§å¢é•¿ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Q/K/V æŠ•å½±é‡å¤è®¡ç®—&lt;/strong&gt;ï¼šä¸‰ç»„æƒé‡çŸ©é˜µç‹¬ç«‹è®¡ç®—ï¼Œé€ æˆç®—åŠ›æµªè´¹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¨¡å‹é‡åŒ–å›°éš¾&lt;/strong&gt;ï¼šæ¿€æ´»åˆ†å¸ƒå­˜åœ¨æç«¯ outliersï¼Œéš¾ä»¥ç¨³å®šè¿›è¡Œä½æ¯”ç‰¹é‡åŒ–ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;QSVD çš„ç›®æ ‡æ˜¯&lt;strong&gt;ç»Ÿä¸€åœ°å¯¹ Q/K/V æƒé‡çŸ©é˜µè¿›è¡Œä½ç§©è¿‘ä¼¼&lt;/strong&gt;å¹¶ç»“åˆ&lt;strong&gt;åè®­ç»ƒé‡åŒ– (PTQ)&lt;/strong&gt;ï¼Œå®ç°ä»¥ä¸‹ä¸‰ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;å‡å°‘å‚æ•°é‡ã€è®¡ç®—é‡ã€ç¼“å­˜å ç”¨ï¼›&lt;/li&gt;
&lt;li&gt;ä¿æŒæ¨¡å‹æ€§èƒ½ï¼›&lt;/li&gt;
&lt;li&gt;æ”¯æŒä½ç²¾åº¦ç¡¬ä»¶éƒ¨ç½²ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/QSVD/figure1.png&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-related-work&#34;&gt;2. Related Work&lt;/h2&gt;
&lt;h3 id=&#34;21-svd-in-large-models&#34;&gt;2.1 SVD in Large Models&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Singular Value Decomposition (SVD)&lt;/strong&gt; æ˜¯ç»å…¸çš„çŸ©é˜µåˆ†è§£æ–¹æ³•ã€‚
å¯¹äºçŸ©é˜µ ( W \in \mathbb{R}^{m \times n} )ï¼Œå¯åˆ†è§£ä¸ºï¼š&lt;/p&gt;
&lt;p&gt;$$
W = U \Sigma V^T
$$&lt;/p&gt;
&lt;p&gt;å…¶ä¸­ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(U, V) ä¸ºæ­£äº¤çŸ©é˜µï¼›&lt;/li&gt;
&lt;li&gt;(\Sigma) ä¸ºå¥‡å¼‚å€¼å¯¹è§’çŸ©é˜µï¼›&lt;/li&gt;
&lt;li&gt;ä¿ç•™å‰ (r) ä¸ªå¥‡å¼‚å€¼å¯å¾—åˆ° rank-(r) è¿‘ä¼¼ï¼š&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;$$
W \approx U_r \Sigma_r V_r^T
$$&lt;/p&gt;</description>
    </item>
    <item>
      <title>SPECVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning</title>
      <link>https://jjl357.github.io/blog/posts/specvlm---enhancingspeculative-decoding-of-video-llms-via-verifier-guided-token-pruning---emnlp25/</link>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/specvlm---enhancingspeculative-decoding-of-video-llms-via-verifier-guided-token-pruning---emnlp25/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/SpecVLM/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference:&lt;/strong&gt; &lt;strong&gt;EMNLP&#39;25&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github:&lt;/strong&gt; &lt;a href=&#34;https://github.com/zju-jiyicheng/SpecVLM&#34;&gt;https://github.com/zju-jiyicheng/SpecVLM&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-motivation&#34;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;Video large language models (Vid-LLMs) have shown strong capabilities in understanding video content. However, their reliance on dense video token representations introduces substantial memory and computational overhead in both prefilling and decoding.&lt;/p&gt;
&lt;p&gt;ä¾‹å¦‚ï¼š
LLaVA-OneVision (Li et al., 2024a) å°†æ¯ä¸€å¸§å¤„ç†ä¸º 196 ä¸ªè§†è§‰ tokenã€‚è‹¥è§†é¢‘ä¸ºä¸¤åˆ†é’Ÿã€60 FPSï¼Œåˆ™æ€» token æ•°é‡è¶…è¿‡ 100 ä¸‡ã€‚
å¦‚æ­¤å¤§é‡çš„ video tokens å¯¼è‡´ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åºåˆ—é•¿åº¦æ€¥å‰§å¢åŠ ï¼›&lt;/li&gt;
&lt;li&gt;Prefill é˜¶æ®µçš„ attention å¼€é”€å‘ˆå¹³æ–¹çº§å¢é•¿ï¼›&lt;/li&gt;
&lt;li&gt;Decoding é˜¶æ®µ KV cache æ€¥é€Ÿè†¨èƒ€ï¼Œæˆä¸ºæ˜¾è‘—çš„ GPU å†…å­˜ç“¶é¢ˆã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åœ¨ autoregressive ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œæ¯æ­¥ç”Ÿæˆçš„ KV cache éƒ½å¿…é¡»ä¸æ¨¡å‹å‚æ•°ä¸€èµ·åŠ è½½ä¸å­˜å‚¨äº GPU æ˜¾å­˜ï¼Œå¯¼è‡´æ˜¾è‘—çš„ memory-bound ç°è±¡ã€‚&lt;/p&gt;</description>
    </item>
    <item>
      <title>AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders</title>
      <link>https://jjl357.github.io/blog/posts/adaspec---selective-knowledge-distillation-for-efficient-speculative-decoders---neurips25-spotlight/</link>
      <pubDate>Mon, 27 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/adaspec---selective-knowledge-distillation-for-efficient-speculative-decoders---neurips25-spotlight/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/AdaSpec/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference:&lt;/strong&gt; &lt;strong&gt;NeurIPS&#39;25 Spotlight&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github:&lt;/strong&gt; &lt;a href=&#34;https://github.com/yuezhouhu/adaspec&#34;&gt;https://github.com/yuezhouhu/adaspec&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;my-thoughts&#34;&gt;My Thoughts&lt;/h2&gt;
&lt;p&gt;è¿™ç¯‡è®ºæ–‡çš„ methods æŒºç®€æ˜çš„ï¼Œæ„Ÿè§‰å¯ä»¥æœ‰ä¸ªæ–° idea:&lt;br&gt;
&lt;strong&gt;å°† MoSD å’Œ AdaSPEC ç»“åˆèµ·æ¥&lt;/strong&gt; â€”â€” é’ˆå¯¹ä¸åŒéš¾åº¦çš„ tokens distill å‡ºä¸åŒçš„ draft modelsï¼Œåˆ©ç”¨ router å°†ä¸åŒéš¾åº¦çš„ tokens é€‰æ‹©æœ€é€‚åˆçš„å¯¹åº” draft model æ¥è¿›è¡Œ SDã€‚&lt;/p&gt;
&lt;p&gt;é—®é¢˜åœ¨äºï¼šå¯¹äºè®ºæ–‡ä¸­æåˆ°çš„â€œhard tokensâ€ï¼Œæ˜¯å¦èƒ½ distill å‡ºä¸€ä¸ªåˆé€‚ä¸”æœ‰ç”¨çš„ draft modelï¼Ÿ&lt;br&gt;
è®ºæ–‡ç»“æœæ˜¾ç¤ºå½“å‰æ–¹æ³•å¯¹è¿™äº› token æ•ˆæœè¾ƒå·®ï¼ˆç”šè‡³æ¯” reference model è¿˜å·®ï¼‰ï¼Œ  å› æ­¤éœ€è¦æ–°çš„æ–¹å¼æ¥æ”¹è¿›è¿™ä¸€éƒ¨åˆ†çš„è’¸é¦ä¸åˆ©ç”¨æœºåˆ¶ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-motivation&#34;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;Speculative Decoding (SD) accelerates large language model inference by employing a small &lt;strong&gt;draft model&lt;/strong&gt; to generate predictions, which are then verified by a larger &lt;strong&gt;target model&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>R-KV: Redundancy-aware KV Cache Compression for Reasoning Models</title>
      <link>https://jjl357.github.io/blog/posts/r-kv---redundancy-aware-kv-cache-compression-for-reasoning-models---neurips25/</link>
      <pubDate>Sat, 25 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/r-kv---redundancy-aware-kv-cache-compression-for-reasoning-models---neurips25/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/RKV/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference:&lt;/strong&gt; NeurIPS&#39;25&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Github:&lt;/strong&gt; &lt;a href=&#34;https://github.com/Zefan-Cai/R-KV&#34;&gt;https://github.com/Zefan-Cai/R-KV&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;my-thoughts&#34;&gt;My Thoughts&lt;/h2&gt;
&lt;p&gt;R-KV é’ˆå¯¹previous worksåœ¨efficient reasoningä¸­ç”±äºåªä¾é attention scoresè€Œé€ æˆè¿‡å¤šåœ°ä¿ç•™äº†redundant tokens(é‡å¤è€Œä¸”å¯¹æ¨ç†æ²¡æœ‰ä¿¡æ¯å¢ç›Šçš„token),R-KVçš„é‡ç‚¹æˆ‘è§‰å¾—æ˜¯å¢åŠ äº†Redundancy Estimation via Semantic Similarityæ¥è§£å†³è¿™ä¸ªé—®é¢˜,å°±Evaluationçš„ç»“æœæ¥è¯´ï¼ŒR-KVçš„æ•ˆæœæ˜¯éå¸¸å¥½çš„ï¼Œå³æå‡äº†Throughputè¿˜maintainäº†performanceï¼Œç”šè‡³åœ¨budgetå……è¶³çš„æƒ…å†µä¸‹è¿˜å¯ä»¥åšåˆ°æç‚¹ã€‚&lt;/p&gt;
&lt;h2 id=&#34;1-motivation&#34;&gt;1. Motivation&lt;/h2&gt;
&lt;p&gt;Reasoning models have demonstrated impressive performance in self-reflection and chain-of-thought reasoning.
However, they often produce excessively long outputs, leading to prohibitively large key-value (KV) caches during inference.&lt;/p&gt;
&lt;p&gt;For instance, a &lt;strong&gt;DeepSeek-R1-Distill-Llama-8B&lt;/strong&gt; model may generate &lt;strong&gt;32K tokens&lt;/strong&gt; to solve a complex math problem, consuming &lt;strong&gt;15.5GB&lt;/strong&gt; of memory to load model weights and &lt;strong&gt;4.1GB&lt;/strong&gt; to store the KV cache.
This long CoT (chain-of-thought) generation necessitates the development of &lt;strong&gt;KV cache compression&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Beyond Attention or Similarity: Maximizing Conditional Diversity for Token Pruning in MLLMs</title>
      <link>https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/</link>
      <pubDate>Fri, 24 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/cdpruner---beyond-attention-or-similarity---maximizing-conditional-diversity-for-token-pruning-in-mllms-neuirips25/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/title.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conference&lt;/strong&gt;: &lt;strong&gt;NeurIPS&#39;25&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;github&lt;/strong&gt;: &lt;a href=&#34;https://github.com/Theia-4869/CDPruner&#34;&gt;https://github.com/Theia-4869/CDPruner&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;my-thoughts&#34;&gt;My Thoughts&lt;/h2&gt;
&lt;p&gt;ç›¸è¾ƒäº Attention-based methods ä¸­çš„ &lt;strong&gt;attention shift&lt;/strong&gt; é—®é¢˜å’Œ Similarity-based methods ä¸­å¿½ç•¥äº† query çš„é—®é¢˜ï¼Œè¿™ç¯‡è®ºæ–‡ä» &lt;strong&gt;å¢åŠ  visual tokens å…¨å±€å¤šæ ·æ€§ï¼ˆåŒæ—¶ä¿æŒå¯¹ query çš„å…³æ³¨ï¼‰&lt;/strong&gt; çš„è§’åº¦å‡ºå‘ï¼Œæå‡ºäº† &lt;strong&gt;CDPruner&lt;/strong&gt;ï¼Œé€šè¿‡å°† token å¤šæ ·æ€§å»ºæ¨¡ä¸º DPPï¼ˆDeterminantal Point Processï¼‰æ±‚è§£é—®é¢˜ï¼Œå®ç°äº† SOTA çš„ pruning æ•ˆæœã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;motivations&#34;&gt;Motivations&lt;/h2&gt;
&lt;p&gt;åœ¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMsï¼‰ä¸­ï¼Œè§†è§‰ token çš„è¾“å…¥é•¿åº¦å¾€å¾€è¿œå¤§äºæ–‡æœ¬ tokenï¼Œä»è€Œå¸¦æ¥é«˜æ˜‚çš„æ¨ç†å¼€é”€ã€‚ä¾‹å¦‚ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LLaVA-1.5 å°†ä¸€å¼  336Ã—336 å›¾åƒè½¬æ¢ä¸º &lt;strong&gt;576 tokens&lt;/strong&gt;ï¼›&lt;/li&gt;
&lt;li&gt;LLaVA-NeXT çš„é«˜åˆ†è¾¨ç‡ç‰ˆæœ¬åœ¨è¾“å…¥åŠ å€çš„æƒ…å†µä¸‹ç”Ÿæˆ &lt;strong&gt;2,880 tokens&lt;/strong&gt;ï¼›&lt;/li&gt;
&lt;li&gt;LongVA å¤„ç† 2,000 å¸§è§†é¢‘æ—¶ç”Ÿæˆè¶…è¿‡ &lt;strong&gt;200K visual tokens&lt;/strong&gt;ï¼›&lt;/li&gt;
&lt;li&gt;LongVILA èƒ½å¤„ç† &lt;strong&gt;6,000 å¸§&lt;/strong&gt;å¹¶äº§ç”Ÿ &lt;strong&gt;è¶…è¿‡ 1M visual tokens&lt;/strong&gt;ï¼Œå¯¼è‡´å·¨å¤§çš„è®¡ç®—æˆæœ¬ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;challenges&#34;&gt;Challenges&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/CDPruner%20-%20Beyond%20Attention%20or%20Similarity%20-/figure1.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;ç°æœ‰çš„è§†è§‰ token å‰ªææ–¹æ³•ä¸»è¦åˆ†ä¸ºä¸¤ç±»ï¼š&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cache-to-Cache: Direct Semantic Communication Between Large Language Models</title>
      <link>https://jjl357.github.io/blog/posts/cache-to-cache---direct-semantic-communication-between-large-language-models/</link>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0000</pubDate>
      <guid>https://jjl357.github.io/blog/posts/cache-to-cache---direct-semantic-communication-between-large-language-models/</guid>
      <description>&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/C2C/title.png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;githubï¼š&lt;a href=&#34;https://github.com/thu-nics/C2C&#34;&gt;https://github.com/thu-nics/C2C&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-motivationåŠ¨æœº--èƒŒæ™¯&#34;&gt;ğŸ’¡ Motivationï¼ˆåŠ¨æœº / èƒŒæ™¯ï¼‰&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/C2C/figure1.png&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç°çŠ¶ï¼šå¤š-LLM ç³»ç»Ÿé€šå¸¸é€šè¿‡ &lt;strong&gt;æ–‡æœ¬ï¼ˆText-to-Text, T2Tï¼‰&lt;/strong&gt; ç›¸äº’é€šä¿¡ â€”â€” ä¸€ä¸ªæ¨¡å‹ç”Ÿæˆæ–‡æœ¬ï¼Œå¦ä¸€ä¸ªæ¨¡å‹å†è¯»å…¥æ–‡æœ¬å¹¶å¤„ç†ã€‚è¿™ç§æ–¹å¼å­˜åœ¨çš„ä¿¡æ¯ç“¶é¢ˆï¼ˆé«˜ç»´å†…éƒ¨è¡¨ç¤ºè¢«å‹æˆæ–‡æœ¬ï¼‰ã€æ­§ä¹‰æ€§ï¼ˆè‡ªç„¶è¯­è¨€æœ¬èº«çš„æ¨¡ç³Šæ€§ï¼‰ä»¥åŠ &lt;strong&gt;ä¸²è¡Œè§£ç å¸¦æ¥çš„å»¶è¿Ÿ&lt;/strong&gt; ç­‰é—®é¢˜ã€‚&lt;/li&gt;
&lt;li&gt;é—®é¢˜ï¼šæ–‡æœ¬é€šä¿¡æ— æ³•å®Œæ•´ä¿ç•™æ¨¡å‹å†…éƒ¨çš„é«˜ç»´è¯­ä¹‰ä¿¡æ¯ï¼ˆä¾‹å¦‚ KV-Cache ä¸­çš„ rich semanticsï¼‰ï¼ŒåŒæ—¶æ–‡æœ¬é€šä¿¡éœ€è¦é€ token è§£ç ï¼Œå¢åŠ é€šä¿¡ä¸æ¨ç†å»¶è¿Ÿã€‚&lt;/li&gt;
&lt;li&gt;æå‡ºçš„é—®é¢˜ï¼ˆæ ¸å¿ƒç ”ç©¶é—®ï¼‰ï¼š&lt;strong&gt;LLMä¹‹é—´èƒ½å¦â€œè¶…è¶Šæ–‡æœ¬â€ç›´æ¥é€šä¿¡ï¼Ÿèƒ½å¦é€šè¿‡å…±äº«/è½¬æ¢/èåˆ KV-Cacheï¼ˆkey/value cacheï¼‰æ¥å®ç°æ›´ä¸°å¯Œã€æ›´ä½å»¶è¿Ÿçš„è¯­ä¹‰é€šä¿¡ï¼Ÿ&lt;/strong&gt;ï¼ˆæ–‡ä¸­ä»¥ â€œCan LLMs communicate beyond text?â€ ä½œæ ¸å¿ƒé©±åŠ¨ã€‚ï¼‰&lt;/li&gt;
&lt;li&gt;ä¸»è¦è§‚å¯Ÿé©±åŠ¨ï¼šä½œè€…çš„ Oracle å®éªŒæ˜¾ç¤º
(1) åœ¨ä¸æ‰©å¤§åºåˆ—é•¿åº¦çš„å‰æä¸‹ï¼Œä¸°å¯Œ KV-Cache å¯ä»¥æå‡å›ç­”è´¨é‡ï¼›
(2) ä¸åŒæ¨¡å‹çš„ KV-Cache åœ¨è¡¨ç¤ºç©ºé—´ä¸Šæ˜¯å¯è½¬æ¢/å¯å¯¹é½çš„ï¼ˆç»è¿‡è®­ç»ƒçš„ç®€å• MLP å¯å°†ä¸€ä¸ªæ¨¡å‹çš„ KV æ˜ å°„åˆ°å¦ä¸€ä¸ªæ¨¡å‹ç©ºé—´ï¼‰ã€‚
è¿™äº›è§‚å¯Ÿæ”¯æŒç”¨ KV-Cache ä½œä¸ºé€šä¿¡åª’ä»‹çš„å¯è¡Œæ€§ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-challengesæŒ‘æˆ˜&#34;&gt;âš” Challengesï¼ˆæŒ‘æˆ˜ï¼‰&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/C2C/figure2.png&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;è·¨æ¨¡å‹çš„ KV-Cache è¡¨ç¤ºå·®å¼‚&lt;/strong&gt;ï¼šä¸åŒæ¨¡å‹ï¼ˆä¸åŒæ—ã€ä¸åŒè§„æ¨¡ã€ä¸åŒ tokenizerï¼‰åœ¨åŒä¸€è¾“å…¥ä¸Šäº§ç”Ÿçš„ KV-Cache åˆ†å¸ƒå·®å¼‚æ˜¾è‘—ï¼ˆt-SNE å¯è§†åŒ–ï¼‰ã€‚å¦‚ä½•å¯é åœ°å°†ä¸€ä¸ªæ¨¡å‹çš„ cache â€œæŠ•å½±â€åˆ°å¦ä¸€ä¸ªæ¨¡å‹çš„è¯­ä¹‰ç©ºé—´å¹¶è¢«æœ‰æ•ˆåˆ©ç”¨æ˜¯æŒ‘æˆ˜ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å¯¹é½é—®é¢˜ï¼ˆtoken-level &amp;amp; layer-levelï¼‰&lt;/strong&gt;ï¼šä¸åŒ tokenizer äº§ç”Ÿä¸åŒ token åˆ’åˆ†ï¼Œä¸”æ¨¡å‹å±‚æ•°ä¸åŒï¼Œå¿…é¡»å¤„ç† token å¯¹é½å’Œå±‚å¯¹é½é—®é¢˜ï¼ˆé¿å…ä¿¡æ¯ä¸¢å¤±æˆ–é”™ä½æ³¨å…¥ï¼‰ã€‚æ–‡ä¸­æå‡ºäº† token è§£ç å† re-encode çš„å¯¹é½ç­–ç•¥å’Œ â€œterminal alignmentâ€ å±‚å¯¹é½ç­–ç•¥ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é¿å…ç ´åæ¥æ”¶è€…åŸæœ‰è¯­ä¹‰&lt;/strong&gt;ï¼šç›´æ¥ç”¨åˆ«äºº cache è¦†ç›–ä¼šç ´åæ¥æ”¶æ¨¡å‹å·²æœ‰è¯­ä¹‰/ç»“æ„ï¼Œéœ€è®¾è®¡æ®‹å·®å¼ã€å¯æ§çš„èåˆæœºåˆ¶ï¼ˆå³ Fuser çš„è®¾è®¡ï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é€‰æ‹©æ€§æ³¨å…¥ï¼ˆå“ªäº›å±‚æ³¨å…¥ã€æ³¨å…¥å¤šå°‘ï¼‰&lt;/strong&gt;ï¼šå¹¶éæ‰€æœ‰å±‚æ³¨å…¥éƒ½æœ‰åˆ©ï¼Œå•å±‚/å¤šå±‚æ³¨å…¥æ•ˆæœå·®å¼‚æ˜æ˜¾ï¼ˆAppendix çš„å•å±‚å®éªŒæ˜¾ç¤ºæœ‰å±‚å¢ç›Šä¹Ÿæœ‰å±‚ä¸‹é™ï¼‰ï¼Œå› æ­¤éœ€è¦ learnable gate æ¥é€‰æ‹©æ³¨å…¥ä½ç½®ä¸æ¯”ä¾‹ã€‚&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ•ˆç‡ / å»¶è¿Ÿæƒè¡¡&lt;/strong&gt;ï¼šè™½ç„¶ C2C ç›®æ ‡æ˜¯é™ä½å»¶è¿Ÿï¼Œä½†åœ¨å®ç°ä¸Šè¦ä¿è¯æŠ•å½±/èåˆæœ¬èº«ä¸ä¼šå¼•å…¥æ¯”æ–‡æœ¬é€šä¿¡æ›´é«˜çš„å¼€é”€ï¼ˆè®¾è®¡è½»é‡ Fuser å¹¶å†»ç»“ä¸»æ¨¡å‹å‚æ•°ä»¥é™ä½è®­ç»ƒ/æ¨ç†æˆæœ¬ï¼‰ã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;-observations--analysis&#34;&gt;ğŸ” Observations / Analysis&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://jjl357.github.io/blog/image/C2C/f34t12.png&#34;&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
